{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VhjK9j1dyDbo"
      },
      "source": [
        "#Training the model and using it for prediction.\n",
        "Google Colab requires only Simpletransformers and wget libraries to be installed. Simpletransformers for working with the transformers models and wget to retrieve the zip file from github repository."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UZyFU2i4S7sD"
      },
      "outputs": [],
      "source": [
        "!pip install simpletransformers\n",
        "!pip install wget"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hje4msyiUC9t"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import wget\n",
        "from simpletransformers.classification import ClassificationModel, ClassificationArgs\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#Evaluation\n",
        "import sklearn\n",
        "from scipy.special import softmax\n",
        "\n",
        "#PARAMETERS\n",
        "CLASSES = 3\n",
        "seed = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PGUmSPTGJ-ut"
      },
      "outputs": [],
      "source": [
        "#Load the training data\n",
        "url = 'https://github.com/markmets/immigration-prediction-EST/raw/main/Annotated_Dataset.csv'\n",
        "dataset = pd.read_csv(url)\n",
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJr0N-L1mHwY"
      },
      "source": [
        "# DATA PREPARATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ItqALMEnprtn"
      },
      "outputs": [],
      "source": [
        "# Change the dataset to 0-2 scale (against, neutral, supportive). Model requires numerical input.\n",
        "dataset = dataset[dataset.stanceConsolidated != 'MH'] #remove nonevaluative\n",
        "dataset['stanceConsolidated'] = dataset['stanceConsolidated'].replace(['1','2'],'0')\n",
        "dataset['stanceConsolidated'] = dataset['stanceConsolidated'].replace(['4','5'],'2')\n",
        "dataset['stanceConsolidated'] = dataset['stanceConsolidated'].replace(['3'],'1')\n",
        "\n",
        "dataset.reset_index(drop=True, inplace=True) #reset indexing after removing rows\n",
        "dataset=dataset[['sentence','stanceConsolidated']] #Drop extra columns\n",
        "dataset= dataset.astype({\"stanceConsolidated\": int}) #label has to be numerical type\n",
        "\n",
        "print(dataset['stanceConsolidated'].value_counts(), '\\nfull len:', len(dataset))\n",
        "\n",
        "dataset.columns = [\"text\", \"labels\"] #rename columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w5Yt5DyTmDFD"
      },
      "outputs": [],
      "source": [
        "#Create evaluation set (20%)\n",
        "train_df, eval_df = train_test_split(dataset, test_size=0.2, stratify=dataset['labels'], random_state=seed)\n",
        "print('train data size: {},   evaluation data size: {}'.format(len(train_df), len(eval_df)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b5JJPvTUrwp8"
      },
      "outputs": [],
      "source": [
        "# Get weights\n",
        "  # Necessary with highly unbalanced datasets\n",
        "\n",
        "unique, counts = np.unique(train_df['labels'], return_counts=True)\n",
        "\n",
        "if CLASSES>=2:\n",
        "    weight_for_0 = (1 / counts[0]) * (len(train_df) / 2.0)\n",
        "    weight_for_1 = (1 / counts[1]) * (len(train_df) / 2.0) #to 2 class\n",
        "if CLASSES>=3:\n",
        "    weight_for_2 = (1 / counts[2]) * (len(train_df) / 2.0) #to 3 class \n",
        "if CLASSES==4:\n",
        "    weight_for_3 = (1 / counts[3]) * (len(train_df) / 2.0) #to 4 class\n",
        "\n",
        "#Weights output\n",
        "class_weight=[weight_for_0,weight_for_1,weight_for_2]\n",
        "print(class_weight)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jSFkEnNReapA"
      },
      "source": [
        "# TRAIN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B1sGsIfHyVhk"
      },
      "outputs": [],
      "source": [
        "### Adds Classification report\n",
        "def clasreport(labels, preds):\n",
        "    return sklearn.metrics.classification_report(labels, preds, output_dict=True)\n",
        "def confmatrix(labels, preds):\n",
        "    return sklearn.metrics.confusion_matrix(labels, preds)\n",
        "\n",
        "### Set model parameters\n",
        "  #Main settings\n",
        "model_args = ClassificationArgs()\n",
        "model_args.manual_seed = seed #manually set seed\n",
        "model_args.use_multiprocessing = False #Not working with XLMRoberta\n",
        "#model_args.labels_list = [\"0\", \"1\", \"2\"] #Errors\n",
        "\n",
        "  #Memory relevant and hyperparameters\n",
        "model_args.num_train_epochs = 2\n",
        "model_args.learning_rate = 5e-5\n",
        "model_args.train_batch_size = 16 #default 8\n",
        "model_args.eval_batch_size = 64\n",
        "model_args.max_seq_length = 512 \n",
        "model_args.warmup_ratio = 0.1\n",
        "\n",
        "  #Saving models\n",
        "model_args.overwrite_output_dir = True\n",
        "model_args.reprocess_input_data = True \n",
        "model_args.no_save = False #Saving models, False is default\n",
        "\n",
        "  #Eval during traing every epoch (currently does it anyways)\n",
        "model_args.evaluate_during_training = False\n",
        "model_args.best_model_dir='output' #directory for output model\n",
        "\n",
        "### TRAIN\n",
        "model = ClassificationModel(\"camembert\", \"EMBEDDIA/est-roberta\", #Choose model\n",
        "                            use_cuda=True, #True applies GPU\n",
        "                             # cuda_device=1, #Choose GPU if multiple\n",
        "                            num_labels=CLASSES, #number of classes (3 for negative, neutral, positive)\n",
        "                            weight= class_weight, #class weights\n",
        "                        args= model_args) #load parameters defined above\n",
        "\n",
        "model.train_model(train_df)\n",
        "result, model_outputs,wrong_predictions  = model.eval_model(eval_df, classification_report=clasreport, confusion_matrix=confmatrix)\n",
        "\n",
        "print(pd.DataFrame(result['classification_report']).transpose()) #show classification report\n",
        "#result[\"confusion_matrix\"] #for numerical confusion matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78tqc6wFBboo"
      },
      "source": [
        "#PREDICT"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/markmets/immigration-prediction-EST/raw/main/All_immigration_sentences.zip #get zip file\n",
        "!unzip /content/All_immigration_sentences.zip #unzip\n",
        "\n",
        "predict_df = pd.read_csv('/content/All_immigration_sentences.csv')  #load csv\n",
        "predict_df"
      ],
      "metadata": {
        "id": "D8Atx6En-CxH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "obII0HA9_3EO"
      },
      "outputs": [],
      "source": [
        "# PREDICT\n",
        "loaded_model = ClassificationModel(\"camembert\", \"/content/outputs/\", use_cuda=True) # Load the saved model, use GPU\n",
        "\n",
        "# PREDICT EXAMPLE SENTENCES\n",
        "#predictions, raw_outputs = loaded_model.predict([\"Ma armastan immigrante!\", \"immigratsiooni teemal on palju diskuteeritud\", \"Rohkem immigrante tähendab vähem töökohti kõikidele põliseestlastele ja see on probleem.\"])\n",
        "#predictions\n",
        "\n",
        "# PREDICT LOADED DATASET\n",
        "# First loading bar is wrong and estimated time is much less than shown. Second is accurate. Ca 20min.\n",
        "predictions, raw_outputs = loaded_model.predict(list(predict_df[predict_df.columns[0]])) #make first column of sentences into list and apply model for prediction\n",
        "print('done:', len(predictions), 'predictions')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "plD1mojM3Mv0"
      },
      "outputs": [],
      "source": [
        "#SAVE THE PREDICTIONS\n",
        "predict_df['predictions_stance']=predictions\n",
        "probabilities_outputs = softmax(raw_outputs, axis=1)\n",
        "predict_df['probabilities_outputs_stance'] = list(probabilities_outputs)\n",
        "predict_df\n",
        "\n",
        "#SAVE AS CSV FILE\n",
        "#predict_df.to_csv('predictedData.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gw1bp1rpA8AD"
      },
      "source": [
        "# Extra - Adding threshold predictions\n",
        "Default predictions chooses the most probable class. This allows to distinguish cases where the probability of most likely class is below or above certain threshold in relation to second best class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H4B8DEzQB-XA"
      },
      "outputs": [],
      "source": [
        "def check_difference(valueList, threshold=0.3): #0.3 means that it has to be at least 30% more probable than any other class\n",
        "    sorted_lst = np.sort(valueList)[::-1] #sort descending\n",
        "    max_value = sorted_lst[0] #take largest\n",
        "    second_max_value = sorted_lst[1] #take second largest\n",
        "    if (max_value - second_max_value) >= threshold: #see if their difference is above threshold\n",
        "        return np.argmax(valueList) #return largest value index\n",
        "    else:\n",
        "        return 'Uncertain' #return this string\n",
        "    \n",
        "predict_df['probabilities_outputs_stance'].apply(check_difference)\n",
        "predict_df['predictions_stance_0.3'] = predict_df['probabilities_outputs_stance'].apply(check_difference)\n",
        "predict_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-IagRCl6GnF1"
      },
      "outputs": [],
      "source": [
        "#Return the certainty of the class (in relation to second best)\n",
        "def check_certainty(valueList): #0.3 means that it has to be at least 30% more probable than any other class\n",
        "    sorted_lst = np.sort(valueList)[::-1] #sort descending\n",
        "    max_value = sorted_lst[0] #take largest\n",
        "    second_max_value = sorted_lst[1] #take second largest\n",
        "    return (max_value - second_max_value)  #see if their difference is above threshold\n",
        "    \n",
        "predict_df['stance_certainty'] = predict_df['probabilities_outputs_stance'].apply(check_certainty)\n",
        "predict_df"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}